{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "# Range of days you want to see\n",
    "StartDate = datetime(year,month,day,14,0) # Never mind with numbers 14 and 0. Just put year, month, and day in.\n",
    "EndDate = datetime(2010,1,3,14,0)\n",
    "\n",
    "# Range of hours that you want to see everyday\n",
    "StartHour = 8\n",
    "EndHour = 18\n",
    "\n",
    "DateRange = (EndDate - StartDate).days\n",
    "HourRange = EndHour - StartHour\n",
    "\n",
    "# Access the website\n",
    "Date = str(StartDate).replace(\"-\",\".\").replace(\" \",\".\")[:-6]\n",
    "url = \"https://www.weather.go.kr/weather/observation/currentweather.jsp?auto_man=m&stn=0&type=t11&reg=100&tm=\"+Date+\"%3A00&x=16&y=5\"\n",
    "wd = webdriver.Chrome(ChromeDriverManager().install())\n",
    "wd.get(url)\n",
    "\n",
    "# Scrape the html file \n",
    "req = wd.page_source\n",
    "soup = BeautifulSoup(req, 'html.parser')\n",
    "\n",
    "# Make a Resualtant diagram to fill in \n",
    "table = soup.select('table') \n",
    "table = str(table)\n",
    "table_df_list = pd.read_html(table)\n",
    "table_df = table_df_list[0]\n",
    "\n",
    "Result = table_df.iloc[:,:2]\n",
    "Result.rename(columns = {'01H' : 'SubZeroRate'}, inplace = True)\n",
    "Result[\"SubZeroRate\"] = 0\n",
    "\n",
    "# Fill in the diagram\n",
    "time = StartDate\n",
    "while((time - EndDate).days < 1):\n",
    "    req = wd.page_source\n",
    "    soup = BeautifulSoup(req,\"html.parser\")\n",
    "    \n",
    "    # Find the table at the website\n",
    "    table = soup.select('table.table_develop3') \n",
    "    table = str(table)\n",
    "    table_df_list = pd.read_html(table)\n",
    "    table_df = table_df_list[0]\n",
    "\n",
    "    # Show the current date that the program is digging in \n",
    "    date = soup.select_one('#observation_text')\n",
    "    date = date[\"value\"]\n",
    "    print(date[:-6])\n",
    "    \n",
    "    # Extract the specific range of hours that you want to look at\n",
    "    Worktime = pd.concat([table_df.iloc[:,0],table_df.iloc[:,StartHour:EndHour+1]],axis = 1)\n",
    "\n",
    "    # Filter out the hours of which temperature is over zero.\n",
    "    Cold = Worktime[Worktime.iloc[:,1:]<0]\n",
    "    Cold = np.array(Cold)\n",
    "\n",
    "    # Calculate the overall subzero hours within each region\n",
    "    for i in range(len(Cold)):\n",
    "        num = (Cold[i]<0).sum()\n",
    "        Result.iloc[i,1] += num\n",
    "        \n",
    "    time += timedelta(days = 1)\n",
    "    Tommorrow = wd.find_element_by_xpath('//*[@id=\"content_weather\"]/div[2]/form/fieldset[2]/ul/li[5]/a')\n",
    "    Tommorrow.click()\n",
    "        \n",
    "for i in range(len(Result)):\n",
    "    Result.iloc[i,1] = Result.iloc[i,1]/36500\n",
    "\n",
    "print(Result)\n",
    "#Result.to_excel('WeatherKorea.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
